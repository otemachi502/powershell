### 目的
Lanscopeオンプレミス版の（以下Lanscope）がどのようにクライアントからのログをバックアップデータとして保持しているか、そしてそれに対して私たちユーザー（情報システム担当）がとるべき施策を整理する。

### Lanscopeのログとバックアップ
Lanscopeが収集する各種ログはSQL Serverのデータ形式(mdf,ldf)で保持しており、このログは長くてもイベント発生から95日経つと削除されて新しいログと入れ替わる。<br>
Lanscopeはこれをバックアップデータとして別の形式で出力することで、95日より前のログを保存可能にしている。バックアップデータは次の3つである。<br>
- システムバックアップデータ(DAT)<br>
- ログ検索データ(DAT)<br>
- ログ一括CSVエクスポート(CSV)<br>

詳しくは公式マニュアル「データ容量メンテナンス 手順書」(C9-366)を参照のこと。<br>
![ログとバックアップデータの関係](https://github.com/user-attachments/assets/b5430a33-9962-459c-b5ef-91c503f7659c "ログとバックアップデータの関係")<br>

まず、ユーザーが考えないといけないのは、このDATやCSVになったバックアップデータの保全である。<br>
3つのうちシステムバックアップデータはシステム復旧の際に必要なもので、フルバックアップを何世代分か保持しておけば十分と思われる。問題は、ログ検索データとログ一括CSVエクスポートの2つである。この2つはインシデント発生時に証拠や原因究明の手掛かりとして使われることを想定している。<br>

### バックアップデータに反映される期間とタイミング

Lanscopeはある日に発生したイベントのログを95日後まで集め続ける（95日が当日を含むか要確認）。なぜ1日のログを95日もかけて集めているのかというと、PCがオフラインだったり通信障害だったりいろんな事情ですぐにはログをサーバー（正式名称：統合マネージャーおよびサブマネージャー）にアップロードできないことがあるからである。<br>
ただしログは毎日ではなく、
- 当日
- 1日後
- 7日後
- 31日後
- 62日後
- 94日後

のタイミングのみで反映されていることには注意が必要(さらに弊社で有効にしているのは31日後まで)。<br>
![ログがバックアップデータに反映されるタイミング](https://github.com/user-attachments/assets/af27e68c-d090-45dd-b481-a9b4334a8c48 "ログがバックアップデータに反映されるタイミング")<br>
例として6月1日に発生したイベントがどのタイミングでログに反映されるか上の表に示した。〇の部分のみがバックアップデータに反映される。<br>
<br>
【追記】<br>
- サーバーにログ(mdf,ldf)が保存されるタイミング<br>
- ログ(mdf,ldf)からバックアップデータ(dat,csv)が作られるタイミング<br>

は互いに独立していて、個々に設定する必要がある。ただし、設定項目の大部分は共通しており結果的に同じタイミングで実行されているのが一般的。<br>

### ログ保存の制約

LanscopeのサーバーはAWS EC2にインストールされておりストレージサイズは柔軟に拡張できるためあまり心配する必要がない。一方でデータベースにはSQL Server Expressを使用しており、1データベースの上限10GB(Lanscopeがログ保存に利用できるのは8GB)の影響は深刻である。<br>

データベースサイズやストレージサイズの制約がある環境のために、Lanscopeではログの種類ごとに保存日数を設定することができる。<br>

> 現行のLanscopeでは、データベースやストレージが不足すると古いデータから勝手に削除していく。<br>
> >新しいデータを保存できなくなるのがDB本来の挙動だが、ログが更新できないと運用しづらいのでこの仕様になっている。<br>
> >余談ながら、この仕様を実現するためにLanscopeは、1DBのログ保存上限をぎりぎりの10GBではなく8GBに設定している(SQL Server Standard環境には当然この制限はない)。<br>
>
> 自動で削除されるにまかせたほうが保持できるログは多くなるかもしれないが、何日分が保持できているか分からないのは内部統制上適切とは言い難い。<br>
> ログ保存日数は明示的に短くするのがベストプラクティスである。ただし、現実的な日数を指定しなければ指定した日数分のログは保持できない。<br>
> やはり十分なデータベースサイズ、ストレージを確保することで、各種ログを95日間保存することが根本的な解決策である。<br>
> >それでも100%ではなく漏れるログも出るが、95日拾えなかったログはシステム運用上どうやっても削除されるのでこれが限界。<br>

ログ保存日数を短くすると、ログ(mdf,ldf)・バックアップデータ(dat,csv)に保存されずに消失するイベントが増える。イベントのログが消失するかどうかは、前節で紹介した保存タイミングに大きく左右されるため、ログ保存日数はこのタイミングを考慮して設定しないと効率が悪い。<br>
> 悪い例として、弊社では現在アプリ稼働ログの保存日数を23日にしているが、これだとバックアップデータに残るのは7日に設定したときと同じである。<br>

ただし、コンソール上では指定した日数分のログを閲覧することはできるので、その点では無駄というわけではなくむしろ有効である。<br>

### バックアップ施策

以上を踏まえて、現在の弊社のバックアップデータの保全施策は次のとおり。<br>
- システムバックアップデータ(DAT)<br>
毎週1回、すべてのデータをS3バケットにアップロード。4世代（4週間分）を保持し、5世代分より古いデータは自動で削除。<br>
- ログ検索データ(DAT)<br>
- ログ一括CSVエクスポート(CSV)<br>
毎日96日前のデータをS3にアップロード。前回バックアップと同じファイルがあれば上書き。ただし古いファイルのほうがファイルサイズが大きいファイルはスキップする。<br>
現在は該当日データは1回しかバックアップしないよう設定しており、実務上前回バックアップとの比較を配慮する必要はない。<br>

        [図: バケット構造]
        s3://midori-lanscope-logs-archive/
        ├─ csv/YYYY/MM/DD/***.csv (旧バックアップ)
        ├─ dat/YYYY/MM/DD/***.dat (旧バックアップ)
        ├─ systemdata/backup-YYYYMMDD/***.dat
        └─ zip/
            └── 2025/
                ├── 07/
                │   ├── 28/
                │   │   └── lanscope-20250728.zip
                │   │       ├── LSPCAT_LLOG20250728.dat
                │   │       ├── Webｱｸｾｽﾛｸﾞ01.csv
                │   │       ├── ｱﾌﾟﾘｹｰｼｮﾝﾀｽｸﾛｸﾞ.csv
                │   │       ├── ｱﾌﾟﾘｹｰｼｮﾝ禁止ﾛｸﾞ.csv
                │   │       ├── ｱﾌﾟﾘ通信ﾛｸﾞ.csv
                │   │       ├── ｴｰｼﾞｪﾝﾄOnOFFﾛｸﾞ.csv
                │   │       ├── ﾌﾟﾘﾝﾄﾛｸﾞ.csv
                │   │       ├── ﾘｱﾙﾀｲﾑｲﾍﾞﾝﾄﾛｸﾞ01.dat
                │   │       ├── ﾛｸﾞｵﾝﾕｰｻﾞｰOnOffﾛｸﾞ.csv
                │   │       ├── 資産ｱﾗｰﾑﾛｸﾞ.csv
                │   │       ├── 操作履歴.csv
                │   │       └── 通信ﾃﾞﾊﾞｲｽﾛｸﾞ01.csv
                │   ├── 29/
                │   │   └── lanscope-20250729.zip
                │   ├── 30/
                │   │   └── lanscope-20250730.zip
                │   └── 31/
                │       └── lanscope-20250731.zip
                └── 08/
                        └── 01/
                        └── lanscope-20250801.zip

S3バケットにアップロードされたデータ（オブジェクト）は下記のライフサイクルルールにより、より低料金で取り出しに時間がかかる（コールドな）ストレージクラスに自動で移される。<br>
- アップロード時: スタンダード<br>
- アップロードから30日経過: Glacier Flexible Retrieval<br>
- アップロードから365日経過: Glacier Deep Archive<br>

S3にアップロードしたデータの削除は今のところ手動。<br>
