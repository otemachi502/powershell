### 目的
Lanscopeオンプレミス版の（以下Lanscope）がどのようにクライアントからのログをバックアップデータとして保持しているか、そしてそれに対して私たちユーザー（情報システム担当）がとるべき施策を整理する。

### Lanscopeのログとバックアップ
Lanscopeが収集する各種ログはSQLのデータ形式(mdf,ldf)で保持しており、ここにあるイベントのログは長くても発生して95日経つと削除されて新しいログと入れ替わる。
Lanscopeはこれをバックアップデータとして別の形式で出力することで、95日より前のログを保存可能にしている。バックアップデータは次の3つである。
- システムバックアップデータ(DAT)<br>
- ログ検索データ(DAT)<br>
- ログ一括CSVエクスポート(CSV)<br>

詳しくは公式マニュアル「データ容量メンテナンス 手順書」(C9-366)を参照のこと。<br>
![ログとバックアップデータの関係](https://github.com/user-attachments/assets/b5430a33-9962-459c-b5ef-91c503f7659c "ログとバックアップデータの関係")<br>

ユーザーが考えないといけないのは、このDATやCSVになったバックアップデータの保全である。<br>
3つのうちシステムバックアップデータはシステム復旧の際に必要なもので、フルバックアップを何世代分か保持しておけば十分と思われる。問題は、ログ検索データとログ一括CSVエクスポートの2つである。この2つはインシデント発生時に証拠や原因究明の手掛かりとして使われることを想定している。<br>

Lanscopeはある日に発生したイベントのログを95日後まで集め続ける（95日が当日を含むか要確認）。なぜ1日のログを95日もかけて集めているのかというと、PCがオフラインだったり通信障害だったりいろんな事情ですぐにはログをサーバー（正式名称：統合マネージャーおよびサブマネージャー）にアップロードできないことがあるからである。
ただしログがバックアップデータに反映されているのは、
- 当日
- 1日後
- 7日後
- 31日後
- 62日後
- 94日後

のタイミングのみであることには注意が必要(さらに弊社で有効にしているのは31日後まで)。<br>
![ログがバックアップデータに反映されるタイミング](https://github.com/user-attachments/assets/f2c9ff13-4dc2-4e11-b5f9-ee465589f8fa "ログがバックアップデータに反映されるタイミング")<br>

LanscopeのサーバーはAWS EC2にインストールされておりストレージサイズは柔軟に拡張できるためあまり心配する必要がない。一方でデータベースにはSQL Server Expressを使用しており、1データベースの上限10GBの影響は深刻である。

データベースサイズやストレージサイズの制約があるユーザーのために、Lanscopeではログの種類ごとに保存日数を設定することができる。

    ちなみに、データベースやストレージに余裕がなくなると、Lanscopeは古いデータから勝手に削除していく（新しいデータを保存できなくなるのがDB本来の挙動らしいが、それでは運用しづらいのでこの仕様になっていると思われる）。それにまかせるのも合理的かもしれないが、何日分が保持できているか分からないのは内部統制上適切とは言い難い。ログ保存日数は明示的に短くするのがベストプラクティスであろう。ただし、ログ保存日数を指定しても指定した値が現実的でなければログが保持できず、結局同じ結果になる。やはり十分なデータベースサイズ、ストレージを確保することで、各種ログを95日間保存できるようにすることが最優先である（それでも100%ではなく漏れるログも出てくるが、95日拾えなかったログはシステム運用上どうやっても削除されるのでこれが限界）。

ログ保存日数を短くすると、上記のタイミングにバックアップデータに反映されないケースが起こりうる。ログ保存日数は、この反映のタイミングを考慮して設定しないと効率が良くない（たとえば弊社ではアプリ稼働ログの保存日数を23日にしているが、これだとイベント発生8日後以降に集めたログがあってもバックアップデータには反映されず、7日に設定するのと同じ結果になる）。ただし、コンソール上では指定した日数分のログを閲覧することはできるので、その点では無駄というわけではなくむしろ有効である。
日数は短くすればするほど、後から収集したログがバックアップに反映されなくなる、つまり消失するログが多くなる。

以上を踏まえて、現在の弊社のバックアップデータの保全施策は次のとおり。
- システムバックアップデータ(DAT)<br>
毎週1回、すべてのデータをS3バケットにアップロード。4世代（4週間分）を保持し、5世代分より古いデータは自動で削除。<br>
- ログ検索データ(DAT)<br>
- ログ一括CSVエクスポート(CSV)<br>
毎月1回、95日前から126日前までのデータをS3バケットにアップロード。前回バックアップと同じファイルがあれば上書き。ただし古いファイルのほうがファイルサイズが大きいファイルはスキップする（結局31日分しかバックアップデータがとれていないのでこの仕様はいらないかも）。<br>

    [図: バケット構造]<br>
    s3://midori-lanscope-logs-archive/<br>
    ├─ csv/YYYY/MM/DD/<br>
    ├─ dat/YYYY/MM/DD/<br>
    └─ systemdata/backup-YYYYMMDD/<br>

S3バケットにアップロードされたデータ（オブジェクト）は下記のライフサイクルルールにより、よりコールドなストレージクラスに自動で移される。
- アップロード時: スタンダード
- アップロードから30日経過: Glacier Flexible Retrieval
- アップロードから365日経過: Glacier Deep Archive
S3にアップロードしたデータの削除は今のところ手動。
